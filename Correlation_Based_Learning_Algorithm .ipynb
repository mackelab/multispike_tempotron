{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation-Based Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Execute all cells containing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import multiprocessing\n",
    "from zipfile import BadZipFile\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_omega(n, omega_coefficient):\n",
    "    omega = np.random.random(n)*omega_coefficient\n",
    "    return omega\n",
    "\n",
    "def desired_fea(n_fea, desired_n, cond = 0, multi = 0):\n",
    "    fea_num = np.zeros(n_fea)\n",
    "    for i in range(desired_n):\n",
    "        if cond:\n",
    "            if multi:\n",
    "                fea_num[i] = multi\n",
    "            else:\n",
    "                fea_num[i] = i + 1\n",
    "        else:\n",
    "            fea_num[i] = 1\n",
    "    return fea_num\n",
    "\n",
    "def kernel_fn(length, tau_mem, tau_syn, time_ij):\n",
    "    time = np.arange(0., length, 1.) #ms\n",
    "    kernel = np.zeros(length)\n",
    "    eta = tau_mem/tau_syn\n",
    "    V_norm = eta**(eta/(eta-1))/(eta-1)\n",
    "    for count in range(length):\n",
    "        kernel[count] = V_norm*(np.exp(-(time[count]-time_ij)/tau_mem)-np.exp(-(time[count]-time_ij)/tau_syn))\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Optimized voltage calculation code by Alex ###\n",
    "\n",
    "def get_memory_len(kernel_array, ratio):\n",
    "    arr = (kernel_array - ratio*kernel_array.max())[::-1]\n",
    "    memory_len = len(kernel_array) - np.searchsorted(arr, 0)\n",
    "    return memory_len\n",
    "\n",
    "def find_first_spike(V, threshold):\n",
    "    # Based on the equivalent code to py_find_1st (https://github.com/roebel/py_find_1st)\n",
    "    ind = np.flatnonzero(V >= threshold)\n",
    "    if len(ind):\n",
    "        return ind[0]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def calculate_Vt(unweighted_input, theta, omega):\n",
    "    spike_time = []\n",
    "    datalen = unweighted_input.shape[1]\n",
    "    V = (omega[:,np.newaxis] * unweighted_input).sum(axis=0)\n",
    "    done = False\n",
    "    while not done:\n",
    "        spike_idx = find_first_spike(V, theta)\n",
    "        if spike_idx == -1:\n",
    "            done = True\n",
    "        else:\n",
    "            spike_time.append(spike_idx)\n",
    "            mem_len = min(ref_memory_len, datalen - spike_idx)\n",
    "            V[spike_idx:spike_idx+mem_len] -= theta * ref_kernel[:mem_len]\n",
    "    return V, spike_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eligibility(data, V_t):\n",
    "    data = np.concatenate((data, np.zeros((n, 100))), axis=1)\n",
    "    dic = dict.fromkeys(range(len(data)))\n",
    "    neuron_eligibility = {value: 0 for value in dic} #To store the eligibility of each neuron\n",
    "    for i, j in zip(*np.where(data)):\n",
    "        kernel = np.zeros(data.shape[1])\n",
    "        mem_len = min(syn_memory_len, data.shape[1] - j)\n",
    "        kernel[j:j+mem_len] += syn_kernel[:mem_len]\n",
    "        eligibility = np.sum(np.multiply(V_t, kernel)) #eligibility += individual correlation, dt = 0.001 \n",
    "        neuron_eligibility[i] += eligibility\n",
    "    return neuron_eligibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def synaptic_update(elig, init_omega, learning_rate, num_spikes, desired_spikes):\n",
    "    D9 = sorted(elig, key=elig.get, reverse=True)[int(n/10)] #9th decile\n",
    "    updated_omega = []\n",
    "    count = 0\n",
    "    while count < len(elig):\n",
    "        if num_spikes < desired_spikes:\n",
    "            if elig[count] > elig[D9]:\n",
    "                updated_omega = np.append(updated_omega, init_omega[count] + learning_rate)\n",
    "            else:\n",
    "                updated_omega = np.append(updated_omega, init_omega[count])\n",
    "        elif num_spikes > desired_spikes:\n",
    "            if elig[count] > elig[D9]:\n",
    "                updated_omega = np.append(updated_omega, init_omega[count] - learning_rate)\n",
    "            else:\n",
    "                updated_omega = np.append(updated_omega, init_omega[count])\n",
    "        else:\n",
    "            return init_omega\n",
    "        count += 1\n",
    "    return updated_omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlation_training(current_omega, n_cycles, data_sets, fea_idx, learning_rate):\n",
    "    cur_omega_list = []\n",
    "    for cycle in range(n_cycles):\n",
    "        for trial in range(cycle*100, cycle*100+100):\n",
    "            clear_output(wait=True)\n",
    "            print(\"Cycle {}, trial {}.\".format(cycle, trial))\n",
    "            input_data = None\n",
    "            while input_data is None:\n",
    "                idx = int(np.random.random()*data_sets)\n",
    "                try:\n",
    "                    input_data = np.load(\"data/data_\"+str(idx)+\".npz\")\n",
    "                    data, presyn_input, markers, n_fea_occur, fea_time, fea_order = input_data['arr_0'], input_data['arr_1'], input_data['arr_2'], input_data['arr_3'], input_data['arr_4'], input_data['arr_5']\n",
    "                except (FileNotFoundError, BadZipFile, KeyError):\n",
    "                    pass\n",
    "            desired_spikes = sum(n_fea_occur * fea_idx)\n",
    "            V_t, spike_time = calculate_Vt(presyn_input, theta, current_omega)\n",
    "            num_spikes = len(spike_time)\n",
    "            if num_spikes != desired_spikes:\n",
    "                elig = eligibility(data, V_t)\n",
    "                current_omega = synaptic_update(elig, current_omega, learning_rate, num_spikes, desired_spikes)\n",
    "        cur_omega_list.append(current_omega)\n",
    "    return cur_omega_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Pre-set Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters and run the cell below.\n",
    "\n",
    "Note: Omega_coefficient of 0.022 was chosen based on the average firing rate of approximately 5 Hz for the postsynaptic neuron with initial synaptic efficacies (omega)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 500 # number of input neurons\n",
    "omega_coefficient = 0.022\n",
    "theta = 1 # threshold\n",
    "tau_mem = 20\n",
    "tau_syn = 5\n",
    "time_ij = 0\n",
    "init_kernel_len = 200\n",
    "\n",
    "# Generate the initial omega for each input neuron\n",
    "np.random.seed(100000)\n",
    "omega = gen_omega(n, omega_coefficient)\n",
    "\n",
    "# Create the PSP kernel, and then remove the negligible tail\n",
    "syn_kernel = kernel_fn(init_kernel_len, tau_mem, tau_syn, time_ij)\n",
    "syn_memory_len = get_memory_len(syn_kernel, ratio=0.001)\n",
    "syn_kernel = syn_kernel[:syn_memory_len]\n",
    "\n",
    "# Create the refractory kernel, and then remove the negligible tail\n",
    "ref_kernel = np.exp(- np.arange(1000) / tau_mem)\n",
    "ref_memory_len = get_memory_len(ref_kernel, ratio=0.001)\n",
    "ref_kernel = ref_kernel[:ref_memory_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation_training function takes 5 arguments, which are current_omega, n_cycles, data_sets, fea_idx, and learning_rate, as inputs and return a list of updated omegas. The updated omega list stores the updated omega after every cycle of training (100 trials each).\n",
    "\n",
    "a. current_omega: intial omega\n",
    "\n",
    "b. n_cycles: number of training cycles required\n",
    "\n",
    "c. data_sets: available number of precomputed data sets in the pool\n",
    "\n",
    "d. fea_idx: indices of features that the multispike tempotron has to identify\n",
    "\n",
    "e. learning_rate: the size of update after each error trial\n",
    "\n",
    "Note: The learning_rate of 0.00001 was chosen according to the original publication (Robert GÃ¼tig, 2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Identification of one feature with one spike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The desired_fea function is used to generate a list of desired feature numbers.\n",
    "\n",
    "To generate one spike to identify only one feature, set desired_n to 1 and cond to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cycles = 1000\n",
    "data_sets = 19999\n",
    "learning_rate = 0.00001\n",
    "n_fea = 10 # Total number of features and distractors\n",
    "desired_n = 1 # Number of desired features\n",
    "\n",
    "# To generate a list of desired feature indices\n",
    "fea_idx = desired_fea(n_fea, desired_n, cond = 0, multi = 0)\n",
    "\n",
    "np.random.seed(int(1e9))\n",
    "corr_omega1F1S_list = correlation_training(omega, n_cycles, data_sets, fea_idx, learning_rate)\n",
    "np.save(\"corr_omega1F1S_list\", corr_omega1F1S_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Identification of one feature with multiple spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate multiple spikes to identify one feature, set desired_n to 1, cond to 1, and multi to the desired number of spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cycles = 1000\n",
    "data_sets = 19999\n",
    "learning_rate = 0.00001\n",
    "n_fea = 10 # Total number of features and distractors\n",
    "desired_n = 1 # Number of desired features\n",
    "\n",
    "# To generate a list of desired feature indices\n",
    "fea_idx = desired_fea(n_fea, desired_n, cond = 1, multi = 5) \n",
    "\n",
    "np.random.seed(int(1e9))\n",
    "corr_omega1F5S_list = correlation_training(omega, n_cycles, data_sets, fea_idx, learning_rate)\n",
    "np.save(\"corr_omega1F5S_list\", corr_omega1F5S_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Identification of multiple features with one spike per feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate one spike to identify multiple features, set desired_n to the number of desired features and cond to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cycles = 1000\n",
    "data_sets = 19999\n",
    "learning_rate = 0.00001\n",
    "n_fea = 10 # Total number of features and distractors\n",
    "desired_n = 5 # Number of desired features\n",
    "\n",
    "# To generate a list of desired feature indices\n",
    "fea_idx = desired_fea(n_fea, desired_n, cond = 0, multi = 0) \n",
    "\n",
    "np.random.seed(int(1e9))\n",
    "corr_omega5F1S_list = correlation_training(omega, n_cycles, data_sets, fea_idx, learning_rate)\n",
    "np.save(\"corr_omega5F1S_list\", corr_omega5F1S_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Identification of multiple features with different number of spikes for different features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate different number of spikes to identify different features, set desired_n to the number of desired features, cond to 1, and multi to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cycles = 1000\n",
    "data_sets = 19999\n",
    "learning_rate = 0.00001\n",
    "n_fea = 10 # Total number of features and distractors\n",
    "desired_n = 5 # Number of desired features\n",
    "\n",
    "# To generate a list of desired feature indices\n",
    "fea_idx = desired_fea(n_fea, desired_n, cond = 1, multi = 0) \n",
    "\n",
    "np.random.seed(int(1e9))\n",
    "corr_omega5FmS_list = correlation_training(omega, n_cycles, data_sets, fea_idx, learning_rate)\n",
    "np.save(\"corr_omega5FmS_list\", corr_omega5FmS_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 Identification of multiple features with a fixed number of spikes (>1) for each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a fixed number of spikes that is greater than 1 for multiple features, set desired_n to the number of desired features, cond to 1, and multi to desired number of spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cycles = 1000\n",
    "data_sets = 19999\n",
    "learning_rate = 0.00001\n",
    "n_fea = 10 # Total number of features and distractors\n",
    "desired_n = 5 # Number of desired features\n",
    "\n",
    "# To generate a list of desired feature indices\n",
    "fea_idx = desired_fea(n_fea, desired_n, cond = 1, multi = 5) \n",
    "\n",
    "np.random.seed(int(1e9))\n",
    "corr_omega5F5S_list = correlation_training(omega, n_cycles, data_sets, fea_idx, learning_rate)\n",
    "np.save(\"corr_omega5F5S_list\", corr_omega5F5S_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cycles = 1000\n",
    "data_sets = 19999\n",
    "learning_rate = 0.00001\n",
    "n_fea = 10 # Total number of features and distractors\n",
    "\n",
    "fea_idx_list = [desired_fea(n_fea, desired_n=1, cond=0, multi=0),\n",
    "                desired_fea(n_fea, desired_n=1, cond=1, multi=5),\n",
    "                desired_fea(n_fea, desired_n=5, cond=0, multi=0),\n",
    "                desired_fea(n_fea, desired_n=5, cond=1, multi=0),\n",
    "                desired_fea(n_fea, desired_n=5, cond=1, multi=5)\n",
    "               ]\n",
    "filenames = [\"corr_omega1F1S_list\",\n",
    "             \"corr_omega1F5S_list\",\n",
    "             \"corr_omega5F1S_list\",\n",
    "             \"corr_omega5FmS_list\",\n",
    "             \"corr_omega5F5S_list\"\n",
    "            ]\n",
    "\n",
    "def run_and_save(filename, fea_idx):\n",
    "    res = multispike_training(omega, n_cycles, data_sets, fea_idx, learning_rate)\n",
    "    np.save(filename, res)\n",
    "\n",
    "with multiprocessing.Pool(5) as pool:\n",
    "    pool.starmap(run_and_save, zip(filenames, fea_idx_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
